# Azerbaijani Automatic Speech Recognition (ASR)

Production-ready end-to-end pipeline for training Whisper-based ASR models for Azerbaijani language.

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Dataset](https://img.shields.io/badge/Dataset-LocalDoc%2Fazerbaijani__asr-orange.svg)](https://huggingface.co/datasets/LocalDoc/azerbaijani_asr)

## ğŸš€ Quick Start

### Option 1: Complete Setup (Recommended)
```bash
# 1. Run environment setup
./scripts/setup_environment.sh

# 2. Download dependencies
python scripts/download_dependencies.py --model small

# 3. Start training
jupyter notebook asr_training_production.ipynb
```

### Option 2: Fast Testing (No Downloads)
```bash
# Install dependencies
pip install -r requirements.txt
pip install evaluate seaborn torchcodec

# Run with streaming (no download needed)
jupyter notebook asr_training_production.ipynb
# Keep SAMPLE_MODE=True and run all cells
```

## ğŸ“ Project Structure

```
automatic_speech_recognition/
â”œâ”€â”€ ğŸ““ asr_training_production.ipynb    # Main production notebook
â”œâ”€â”€ ğŸ““ azerbaijani_asr_training.ipynb   # Original training notebook
â”œâ”€â”€ ğŸ train_sample.py                  # Standalone training script
â”œâ”€â”€ ğŸ“‹ requirements.txt                 # Python dependencies
â”œâ”€â”€ ğŸ“– README.md                        # This file
â”œâ”€â”€ ğŸ“– README_PRODUCTION.md             # Detailed production guide
â”‚
â”œâ”€â”€ scripts/                            # ğŸ› ï¸ Utility scripts
â”‚   â”œâ”€â”€ download_data.py                # Dataset downloader
â”‚   â”œâ”€â”€ download_model.py               # Model downloader
â”‚   â”œâ”€â”€ download_dependencies.py        # Combined downloader
â”‚   â”œâ”€â”€ setup_environment.sh            # Environment setup
â”‚   â””â”€â”€ README.md                       # Scripts documentation
â”‚
â”œâ”€â”€ charts/                             # ğŸ“Š Generated visualizations
â”‚   â”œâ”€â”€ duration_distribution.png
â”‚   â”œâ”€â”€ text_length_distribution.png
â”‚   â”œâ”€â”€ training_loss_curve.png
â”‚   â”œâ”€â”€ validation_wer_curve.png
â”‚   â””â”€â”€ results_summary.png
â”‚
â”œâ”€â”€ outputs/                            # ğŸ“ˆ Metrics and results
â”‚   â”œâ”€â”€ *_config.json                   # Experiment configurations
â”‚   â”œâ”€â”€ *_device_info.json              # Hardware information
â”‚   â”œâ”€â”€ *_training_history.csv          # Training logs
â”‚   â”œâ”€â”€ *_eval_history.csv              # Evaluation logs
â”‚   â”œâ”€â”€ *_validation_results.json       # Validation metrics
â”‚   â”œâ”€â”€ *_test_results.json             # Test metrics
â”‚   â””â”€â”€ *_sample_predictions.csv        # Example predictions
â”‚
â”œâ”€â”€ artifacts/                          # ğŸ’¾ Trained models
â”‚   â””â”€â”€ {experiment_name}_final/
â”‚       â”œâ”€â”€ config.json                 # Model configuration
â”‚       â”œâ”€â”€ model.safetensors           # Model weights
â”‚       â”œâ”€â”€ preprocessor_config.json    # Preprocessing config
â”‚       â”œâ”€â”€ tokenizer_config.json       # Tokenizer config
â”‚       â”œâ”€â”€ experiment_metadata.json    # Complete experiment info
â”‚       â””â”€â”€ README.md                   # Model documentation
â”‚
â”œâ”€â”€ data/                               # ğŸ’¿ Dataset cache
â”‚   â””â”€â”€ dataset_cache/                  # Downloaded dataset
â”‚
â””â”€â”€ models/                             # ğŸ¤– Model cache
    â””â”€â”€ [huggingface model cache]       # Downloaded Whisper models
```

## âœ¨ Features

### Production Notebook
- âœ… **Complete ML Pipeline** (14 stages from data to deployment)
- âœ… **Industry Best Practices** (reproducibility, logging, versioning)
- âœ… **Automated Artifact Management** (charts, metrics, models)
- âœ… **Comprehensive Evaluation** (WER, sample predictions, visualizations)
- âœ… **Hardware Auto-Detection** (CPU/GPU/MPS)
- âœ… **Streaming Mode Support** (no download required for testing)
- âœ… **Train/Val/Test Splits** (80/10/10, no data leakage)
- âœ… **Fixed Random Seeds** (fully reproducible results)

### Scripts
- ğŸ”½ **download_data.py** - Dataset downloader with retry logic
- ğŸ”½ **download_model.py** - Pre-download Whisper models
- ğŸ”½ **download_dependencies.py** - Download everything at once
- âš™ï¸ **setup_environment.sh** - Complete environment setup

## ğŸ“Š Dataset

**Source**: [LocalDoc/azerbaijani_asr](https://huggingface.co/datasets/LocalDoc/azerbaijani_asr)

| Metric | Value |
|--------|-------|
| Samples | 351,019 |
| Duration | ~334 hours |
| Size | 38.5 GB |
| Format | WAV (16kHz) |
| Language | Azerbaijani |
| License | CC-BY-NC-4.0 |

**Duration Distribution:**
- 0-2 sec: 36.1%
- 2-5 sec: 47.2%
- 5-10 sec: 14.6%
- 10-20 sec: 2.0%
- 20+ sec: 0.1%

## ğŸ¤– Supported Models

| Model | Parameters | Size | Use Case |
|-------|-----------|------|----------|
| whisper-tiny | 39M | ~150 MB | Fast testing |
| whisper-base | 74M | ~290 MB | CPU training |
| **whisper-small** | **244M** | **~970 MB** | **Recommended** |
| whisper-medium | 769M | ~3 GB | GPU training |
| whisper-large-v2 | 1.5B | ~6 GB | Best accuracy |

## ğŸ“– Usage

### 1. Setup Environment
```bash
# Option A: Automated setup
./scripts/setup_environment.sh

# Option B: Manual setup
pip install -r requirements.txt
pip install evaluate seaborn torchcodec
mkdir -p data charts outputs artifacts models
```

### 2. Download Resources
```bash
# Option A: Download everything
python scripts/download_dependencies.py --model small

# Option B: Dataset only
python scripts/download_data.py

# Option C: Model only
python scripts/download_model.py --model openai/whisper-small

# Option D: Use streaming (no downloads)
# Just run the notebook with SAMPLE_MODE=True
```

### 3. Train Model
```bash
# Option A: Production notebook (recommended)
jupyter notebook asr_training_production.ipynb
# Set SAMPLE_MODE=True for testing or False for full training

# Option B: Standalone script
python train_sample.py
```

### 4. Use Trained Model
```python
from transformers import pipeline

# Load model
pipe = pipeline(
    "automatic-speech-recognition",
    model="./artifacts/{experiment_name}_final"
)

# Transcribe audio
result = pipe("audio.wav")
print(result["text"])
```

## ğŸ¯ Training Modes

### Sample Mode (Testing)
- **Samples**: 500
- **Duration**: ~10-20 minutes
- **Hardware**: CPU OK
- **Purpose**: Quick testing, development
- **Config**: `SAMPLE_MODE=True`

### Full Mode (Production)
- **Samples**: 351,019
- **Duration**: Several hours
- **Hardware**: GPU recommended
- **Purpose**: Production model
- **Config**: `SAMPLE_MODE=False`

## ğŸ“ˆ Expected Results

| Metric | Sample Mode | Full Mode |
|--------|-------------|-----------|
| WER (Validation) | 25-35% | 15-25% |
| WER (Test) | 25-35% | 15-25% |
| Training Time | 10-20 min | 3-8 hours |
| Hardware | CPU | GPU |

Lower WER = Better (0% = perfect transcription)

## ğŸ”§ Configuration

Edit notebook Cell 1 or modify `CONFIG` dict:

```python
CONFIG = {
    # Mode
    "sample_mode": True,              # True=testing, False=production
    "sample_size": 500,                # Samples in sample mode

    # Model
    "model_name": "openai/whisper-small",
    "language": "azerbaijani",

    # Training
    "batch_size": 8,
    "num_epochs": 3,
    "learning_rate": 1e-5,

    # Reproducibility
    "random_seed": 42,

    # Splits
    "train_ratio": 0.8,
    "val_ratio": 0.1,
    "test_ratio": 0.1,
}
```

## ğŸ“Š Generated Outputs

After training, you'll find:

### Charts (`/charts`)
- Duration/text distributions
- Training loss curves
- Validation WER curves
- Results summary dashboard

### Metrics (`/outputs`)
- Configuration JSONs
- Training/eval history (CSV)
- Validation/test results
- Sample predictions
- Data validation reports

### Models (`/artifacts`)
- Complete trained model
- Preprocessor & tokenizer
- Experiment metadata
- Model README

## ğŸ’» Hardware Requirements

| Mode | CPU | RAM | GPU | Disk |
|------|-----|-----|-----|------|
| Sample | âœ… Any | 8GB | âŒ Not needed | 5GB |
| Full | âš ï¸ Slow | 16GB | âœ… 8GB+ VRAM | 50GB |

**Supported Devices:**
- CUDA GPUs (NVIDIA)
- Apple Silicon (MPS)
- CPU (slow for full training)

## ğŸ› Troubleshooting

### Network/SSL Issues
```bash
# Scripts include SSL bypass for corporate networks
export HF_HUB_DISABLE_XET=1
export HF_HUB_DISABLE_SSL_VERIFY=1
```

### Out of Memory
```python
# Reduce batch size
CONFIG["batch_size"] = 4  # or 2

# Or use smaller model
CONFIG["model_name"] = "openai/whisper-tiny"
```

### Slow Training
- Use sample mode for testing
- Enable GPU if available
- Use smaller model (whisper-tiny)
- Reduce sample_size

See [docs/README_PRODUCTION.md](docs/README_PRODUCTION.md) for detailed troubleshooting.

## ğŸ“š Documentation

- **[docs/](docs/)** - Complete documentation index
- **[docs/README_PRODUCTION.md](docs/README_PRODUCTION.md)** - Detailed production guide
- **[docs/SCRIPTS.md](docs/SCRIPTS.md)** - Scripts documentation
- **[Notebook](asr_training_production.ipynb)** - Inline documentation

## ğŸ”¬ Reproducibility

All experiments are fully reproducible:
- âœ… Fixed random seeds
- âœ… Version-controlled configurations
- âœ… Complete environment logs
- âœ… Deterministic data splits

To reproduce:
1. Use same `random_seed`
2. Use same configuration
3. Follow same data preprocessing steps

## ğŸ“„ License

- **Code**: MIT License
- **Dataset**: CC-BY-NC-4.0 (non-commercial use only)
- **Model**: OpenAI Whisper License

## ğŸ™ Acknowledgments

- **Dataset**: [LocalDoc/azerbaijani_asr](https://huggingface.co/datasets/LocalDoc/azerbaijani_asr)
- **Model**: [OpenAI Whisper](https://github.com/openai/whisper)
- **Framework**: [Hugging Face Transformers](https://github.com/huggingface/transformers)

## ğŸ“ Support

For issues or questions:
1. Check the documentation (README_PRODUCTION.md, scripts/README.md)
2. Review troubleshooting sections
3. Check original dataset/model repositories

## ğŸ—ºï¸ Roadmap

- [ ] Add data augmentation
- [ ] Support for other Whisper variants
- [ ] Model quantization for deployment
- [ ] Real-time inference support
- [ ] Multi-GPU training
- [ ] Distributed training support

---

**Version**: 1.0
**Last Updated**: January 11, 2026
**Python**: 3.10+
**Status**: Production Ready âœ…
