{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azerbaijani ASR Model Training - Production Pipeline\n",
    "\n",
    "**End-to-end ASR training workflow following industry best practices**\n",
    "\n",
    "## Overview\n",
    "This notebook implements a complete pipeline for training an Automatic Speech Recognition model for Azerbaijani language using Whisper architecture.\n",
    "\n",
    "## Project Structure\n",
    "```\n",
    ".\n",
    "├── charts/      # All visualizations (PNG/SVG)\n",
    "├── outputs/     # Metrics, tables, evaluation summaries\n",
    "├── artifacts/   # Trained models, processors, configs\n",
    "└── data/        # Dataset cache\n",
    "```\n",
    "\n",
    "## Features\n",
    "- Reproducible training with fixed random seeds\n",
    "- Proper train/val/test splits with no data leakage\n",
    "- Comprehensive evaluation metrics and visualizations\n",
    "- Model versioning and artifact management\n",
    "- Production-ready code with error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:43:31.305436Z",
     "iopub.status.busy": "2026-01-11T11:43:31.305051Z",
     "iopub.status.idle": "2026-01-11T11:43:31.318979Z",
     "shell.execute_reply": "2026-01-11T11:43:31.318448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Experiment: whisper_azerbaijani_20260111_154331\n",
      "======================================================================\n",
      "Mode: SAMPLE\n",
      "Model: openai/whisper-tiny\n",
      "Dataset: LocalDoc/azerbaijani_asr\n",
      "Random Seed: 42\n",
      "\n",
      "Configuration saved to: outputs/whisper_azerbaijani_20260111_154331_config.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Central configuration for entire pipeline\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Project directories\n",
    "PROJECT_ROOT = Path(\".\")\n",
    "CHARTS_DIR = PROJECT_ROOT / \"charts\"\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
    "ARTIFACTS_DIR = PROJECT_ROOT / \"artifacts\"\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "\n",
    "# Create directories\n",
    "for directory in [CHARTS_DIR, OUTPUTS_DIR, ARTIFACTS_DIR, DATA_DIR]:\n",
    "    directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Training configuration\n",
    "CONFIG = {\n",
    "    # Model settings\n",
    "    \"model_name\": \"openai/whisper-tiny\",  # CHANGED: Using tiny for faster download\n",
    "    \"language\": \"azerbaijani\",\n",
    "    \"task\": \"transcribe\",\n",
    "    \n",
    "    # Dataset settings\n",
    "    \"dataset_name\": \"LocalDoc/azerbaijani_asr\",\n",
    "    \"sample_mode\": True,  # Set False for full training\n",
    "    \"sample_size\": 500,   # Number of samples in sample mode\n",
    "    \"sampling_rate\": 16000,\n",
    "    \n",
    "    # Data splits\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    \"batch_size\": 8,\n",
    "    \"num_epochs\": 3,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"warmup_steps\": 500,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"max_steps\": -1,  # -1 for full epochs\n",
    "    \"fp16\": True,\n",
    "    \n",
    "    # Evaluation settings\n",
    "    \"eval_steps\": 100,\n",
    "    \"save_steps\": 500,\n",
    "    \"logging_steps\": 50,\n",
    "    \"save_total_limit\": 3,\n",
    "    \n",
    "    # Reproducibility\n",
    "    \"random_seed\": 42,\n",
    "    \n",
    "    # Experiment tracking\n",
    "    \"experiment_name\": f\"whisper_azerbaijani_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "}\n",
    "\n",
    "# Adjust config for sample mode\n",
    "if CONFIG[\"sample_mode\"]:\n",
    "    CONFIG.update({\n",
    "        \"batch_size\": 4,\n",
    "        \"num_epochs\": 1,\n",
    "        \"max_steps\": 100,\n",
    "        \"eval_steps\": 50,\n",
    "        \"save_steps\": 50,\n",
    "        \"warmup_steps\": 20,\n",
    "    })\n",
    "\n",
    "# Save configuration\n",
    "config_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_config.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2, default=str)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Experiment: {CONFIG['experiment_name']}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Mode: {'SAMPLE' if CONFIG['sample_mode'] else 'FULL TRAINING'}\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")\n",
    "print(f\"Dataset: {CONFIG['dataset_name']}\")\n",
    "print(f\"Random Seed: {CONFIG['random_seed']}\")\n",
    "print(f\"\\nConfiguration saved to: {config_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:43:31.354136Z",
     "iopub.status.busy": "2026-01-11T11:43:31.353915Z",
     "iopub.status.idle": "2026-01-11T11:43:31.433337Z",
     "shell.execute_reply": "2026-01-11T11:43:31.432923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SSL verification disabled (corporate network compatibility)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SSL Configuration for Corporate Networks\n",
    "# ============================================================\n",
    "\n",
    "import ssl\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Disable Xet storage and SSL verification\n",
    "os.environ['HF_HUB_DISABLE_XET'] = '1'\n",
    "os.environ['HF_HUB_DISABLE_SSL_VERIFY'] = '1'\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = ''\n",
    "\n",
    "sys.modules['hf_xet'] = None\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "warnings.filterwarnings('ignore', message='Unverified HTTPS request')\n",
    "\n",
    "import requests\n",
    "_orig_request = requests.Session.request\n",
    "\n",
    "def _patched_request(self, method, url, **kwargs):\n",
    "    kwargs['verify'] = False\n",
    "    return _orig_request(self, method, url, **kwargs)\n",
    "\n",
    "requests.Session.request = _patched_request\n",
    "\n",
    "print(\"✓ SSL verification disabled (corporate network compatibility)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:43:31.435461Z",
     "iopub.status.busy": "2026-01-11T11:43:31.435252Z",
     "iopub.status.idle": "2026-01-11T11:43:33.686554Z",
     "shell.execute_reply": "2026-01-11T11:43:33.686005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Set Random Seeds for Reproducibility\n",
    "# ============================================================\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seeds for reproducibility across all libraries.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # For deterministic behavior (may impact performance)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Set environment variable for Python hashing\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(CONFIG[\"random_seed\"])\n",
    "print(f\"✓ Random seed set to {CONFIG['random_seed']} for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:43:33.688954Z",
     "iopub.status.busy": "2026-01-11T11:43:33.688701Z",
     "iopub.status.idle": "2026-01-11T11:43:48.460451Z",
     "shell.execute_reply": "2026-01-11T11:43:48.459096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Import Required Libraries\n",
    "# ============================================================\n",
    "\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Hugging Face libraries\n",
    "from datasets import load_dataset, Dataset, DatasetDict, Audio\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    TrainerCallback,\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Hardware Detection and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:43:48.470638Z",
     "iopub.status.busy": "2026-01-11T11:43:48.467963Z",
     "iopub.status.idle": "2026-01-11T11:43:48.481372Z",
     "shell.execute_reply": "2026-01-11T11:43:48.480864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Hardware Information\n",
      "======================================================================\n",
      "Device: Apple Silicon (MPS)\n",
      "FP16 Training: Disabled\n",
      "\n",
      "Device info saved to: outputs/whisper_azerbaijani_20260111_154331_device_info.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Detect Available Hardware\n",
    "# ============================================================\n",
    "\n",
    "def detect_device() -> Dict[str, Any]:\n",
    "    \"\"\"Detect available hardware and return device info.\"\"\"\n",
    "    device_info = {\n",
    "        \"device\": \"cpu\",\n",
    "        \"device_name\": \"CPU\",\n",
    "        \"memory_gb\": None,\n",
    "        \"fp16_available\": False,\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device_info[\"device\"] = \"cuda\"\n",
    "        device_info[\"device_name\"] = torch.cuda.get_device_name(0)\n",
    "        device_info[\"memory_gb\"] = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        device_info[\"fp16_available\"] = True\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_info[\"device\"] = \"mps\"\n",
    "        device_info[\"device_name\"] = \"Apple Silicon (MPS)\"\n",
    "        device_info[\"fp16_available\"] = False  # MPS doesn't support fp16 mixed precision\n",
    "    \n",
    "    return device_info\n",
    "\n",
    "device_info = detect_device()\n",
    "\n",
    "# Update config based on hardware\n",
    "if not device_info[\"fp16_available\"]:\n",
    "    CONFIG[\"fp16\"] = False\n",
    "\n",
    "# Save device info\n",
    "device_info_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_device_info.json\"\n",
    "with open(device_info_path, 'w') as f:\n",
    "    json.dump(device_info, f, indent=2)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Hardware Information\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Device: {device_info['device_name']}\")\n",
    "if device_info['memory_gb']:\n",
    "    print(f\"Memory: {device_info['memory_gb']:.2f} GB\")\n",
    "print(f\"FP16 Training: {'Enabled' if CONFIG['fp16'] else 'Disabled'}\")\n",
    "print(f\"\\nDevice info saved to: {device_info_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Loading and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:43:48.484399Z",
     "iopub.status.busy": "2026-01-11T11:43:48.483878Z",
     "iopub.status.idle": "2026-01-11T11:44:30.518851Z",
     "shell.execute_reply": "2026-01-11T11:44:30.516143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Loading dataset: LocalDoc/azerbaijani_asr\n",
      "Mode: Sample (500 samples)\n",
      "Loading with streaming mode...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe58d4d28b94ce089eca78e434d798e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking 500 samples from stream...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de169fb7fa8e4485b8ce2afe1dcc0297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading samples:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Dataset loaded successfully\n",
      "Train samples: 500\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load Dataset\n",
    "# ============================================================\n",
    "\n",
    "def load_asr_dataset(config: Dict) -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Load ASR dataset with streaming support.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        DatasetDict with train split\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset: {config['dataset_name']}\")\n",
    "    print(f\"Mode: {'Sample ({} samples)'.format(config['sample_size']) if config['sample_mode'] else 'Full dataset'}\")\n",
    "    \n",
    "    # Check if local data exists\n",
    "    local_path = DATA_DIR / \"dataset_cache\"\n",
    "    \n",
    "    if local_path.exists() and not config['sample_mode']:\n",
    "        print(f\"Loading from local cache: {local_path}\")\n",
    "        from datasets import load_from_disk\n",
    "        dataset = load_from_disk(str(local_path))\n",
    "    else:\n",
    "        print(\"Loading with streaming mode...\")\n",
    "        dataset_stream = load_dataset(\n",
    "            config['dataset_name'],\n",
    "            streaming=True,\n",
    "            trust_remote_code=False\n",
    "        )\n",
    "        \n",
    "        # Take samples if in sample mode\n",
    "        if config['sample_mode']:\n",
    "            n_samples = config['sample_size']\n",
    "            print(f\"Taking {n_samples} samples from stream...\")\n",
    "            \n",
    "            samples = list(tqdm(\n",
    "                dataset_stream[\"train\"].take(n_samples),\n",
    "                total=n_samples,\n",
    "                desc=\"Loading samples\"\n",
    "            ))\n",
    "            \n",
    "            dataset = DatasetDict({\n",
    "                \"train\": Dataset.from_list(samples)\n",
    "            })\n",
    "        else:\n",
    "            # For full dataset, download and cache\n",
    "            dataset = load_dataset(config['dataset_name'])\n",
    "            dataset.save_to_disk(str(local_path))\n",
    "            print(f\"Dataset cached to: {local_path}\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Load dataset\n",
    "print(\"=\" * 70)\n",
    "dataset = load_asr_dataset(CONFIG)\n",
    "print(\"\\n✓ Dataset loaded successfully\")\n",
    "print(f\"Train samples: {len(dataset['train'])}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:30.536233Z",
     "iopub.status.busy": "2026-01-11T11:44:30.535290Z",
     "iopub.status.idle": "2026-01-11T11:44:30.667074Z",
     "shell.execute_reply": "2026-01-11T11:44:30.666599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Data Validation\n",
      "======================================================================\n",
      "\n",
      "Total Samples: 500\n",
      "Columns: audio, text, duration, audio_file\n",
      "Audio Column: audio\n",
      "Text Column: text\n",
      "\n",
      "Missing Values:\n",
      "  audio: 0\n",
      "  text: 0\n",
      "\n",
      "Duration Statistics:\n",
      "  mean: 5.75\n",
      "  median: 5.08\n",
      "  std: 2.95\n",
      "  min: 0.71\n",
      "  max: 16.57\n",
      "  total_hours: 0.80\n",
      "\n",
      "Text Statistics:\n",
      "  mean_length: 85.00\n",
      "  median_length: 77.50\n",
      "  min_length: 11.00\n",
      "  max_length: 237.00\n",
      "\n",
      "✓ No validation issues found\n",
      "\n",
      "Validation results saved to: outputs/whisper_azerbaijani_20260111_154331_validation.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Data Validation and Schema Checks\n",
    "# ============================================================\n",
    "\n",
    "def validate_dataset(dataset: Dataset) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate dataset schema and content.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with validation results\n",
    "    \"\"\"\n",
    "    validation_results = {\n",
    "        \"total_samples\": len(dataset),\n",
    "        \"columns\": list(dataset.features.keys()),\n",
    "        \"missing_values\": {},\n",
    "        \"duration_stats\": {},\n",
    "        \"text_stats\": {},\n",
    "        \"issues\": [],\n",
    "    }\n",
    "    \n",
    "    # Check for required columns\n",
    "    sample = dataset[0]\n",
    "    audio_col = \"audio\" if \"audio\" in sample else \"path\"\n",
    "    text_col = next((col for col in [\"sentence\", \"text\", \"transcription\"] if col in sample), None)\n",
    "    \n",
    "    if audio_col not in sample:\n",
    "        validation_results[\"issues\"].append(\"Missing audio column\")\n",
    "    if text_col is None:\n",
    "        validation_results[\"issues\"].append(\"Missing text column\")\n",
    "    \n",
    "    validation_results[\"audio_column\"] = audio_col\n",
    "    validation_results[\"text_column\"] = text_col\n",
    "    \n",
    "    # Check for missing/empty values\n",
    "    for col in [audio_col, text_col]:\n",
    "        if col:\n",
    "            empty_count = sum(1 for item in dataset if not item.get(col))\n",
    "            validation_results[\"missing_values\"][col] = empty_count\n",
    "            if empty_count > 0:\n",
    "                validation_results[\"issues\"].append(f\"{col} has {empty_count} missing values\")\n",
    "    \n",
    "    # Analyze durations if available\n",
    "    if \"duration\" in sample:\n",
    "        durations = [item[\"duration\"] for item in dataset if item.get(\"duration\")]\n",
    "        validation_results[\"duration_stats\"] = {\n",
    "            \"mean\": np.mean(durations),\n",
    "            \"median\": np.median(durations),\n",
    "            \"std\": np.std(durations),\n",
    "            \"min\": np.min(durations),\n",
    "            \"max\": np.max(durations),\n",
    "            \"total_hours\": np.sum(durations) / 3600,\n",
    "        }\n",
    "    \n",
    "    # Analyze text lengths\n",
    "    if text_col:\n",
    "        text_lengths = [len(item[text_col]) for item in dataset if item.get(text_col)]\n",
    "        validation_results[\"text_stats\"] = {\n",
    "            \"mean_length\": np.mean(text_lengths),\n",
    "            \"median_length\": np.median(text_lengths),\n",
    "            \"min_length\": np.min(text_lengths),\n",
    "            \"max_length\": np.max(text_lengths),\n",
    "        }\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "# Validate dataset\n",
    "print(\"=\" * 70)\n",
    "print(\"Data Validation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "validation_results = validate_dataset(dataset[\"train\"])\n",
    "\n",
    "# Print validation results\n",
    "print(f\"\\nTotal Samples: {validation_results['total_samples']}\")\n",
    "print(f\"Columns: {', '.join(validation_results['columns'])}\")\n",
    "print(f\"Audio Column: {validation_results['audio_column']}\")\n",
    "print(f\"Text Column: {validation_results['text_column']}\")\n",
    "\n",
    "if validation_results['missing_values']:\n",
    "    print(\"\\nMissing Values:\")\n",
    "    for col, count in validation_results['missing_values'].items():\n",
    "        print(f\"  {col}: {count}\")\n",
    "\n",
    "if validation_results['duration_stats']:\n",
    "    print(\"\\nDuration Statistics:\")\n",
    "    for key, value in validation_results['duration_stats'].items():\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "\n",
    "if validation_results['text_stats']:\n",
    "    print(\"\\nText Statistics:\")\n",
    "    for key, value in validation_results['text_stats'].items():\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "\n",
    "if validation_results['issues']:\n",
    "    print(\"\\n⚠️  Issues Found:\")\n",
    "    for issue in validation_results['issues']:\n",
    "        print(f\"  - {issue}\")\n",
    "else:\n",
    "    print(\"\\n✓ No validation issues found\")\n",
    "\n",
    "# Save validation results\n",
    "validation_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_validation.json\"\n",
    "with open(validation_path, 'w') as f:\n",
    "    json.dump(validation_results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nValidation results saved to: {validation_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:30.673579Z",
     "iopub.status.busy": "2026-01-11T11:44:30.673304Z",
     "iopub.status.idle": "2026-01-11T11:44:34.456454Z",
     "shell.execute_reply": "2026-01-11T11:44:34.455434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating exploratory data analysis visualizations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Duration distribution chart saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Text length distribution chart saved\n",
      "✓ Data summary table saved\n",
      "\n",
      "All visualizations saved to: charts\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Exploratory Data Analysis - Visualizations\n",
    "# ============================================================\n",
    "\n",
    "def create_eda_visualizations(dataset: Dataset, validation_results: Dict, save_dir: Path):\n",
    "    \"\"\"\n",
    "    Create exploratory data analysis visualizations.\n",
    "    \"\"\"\n",
    "    text_col = validation_results[\"text_column\"]\n",
    "    \n",
    "    # Duration distribution (if available)\n",
    "    if \"duration\" in dataset[0]:\n",
    "        durations = [item[\"duration\"] for item in dataset if item.get(\"duration\")]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Histogram\n",
    "        ax1.hist(durations, bins=50, edgecolor='black', alpha=0.7)\n",
    "        ax1.set_xlabel('Duration (seconds)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Audio Duration Distribution')\n",
    "        ax1.axvline(np.mean(durations), color='r', linestyle='--', label=f'Mean: {np.mean(durations):.2f}s')\n",
    "        ax1.axvline(np.median(durations), color='g', linestyle='--', label=f'Median: {np.median(durations):.2f}s')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Box plot\n",
    "        ax2.boxplot(durations, vert=True)\n",
    "        ax2.set_ylabel('Duration (seconds)')\n",
    "        ax2.set_title('Audio Duration Box Plot')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir / \"duration_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✓ Duration distribution chart saved\")\n",
    "    \n",
    "    # Text length distribution\n",
    "    if text_col:\n",
    "        text_lengths = [len(item[text_col]) for item in dataset if item.get(text_col)]\n",
    "        word_counts = [len(item[text_col].split()) for item in dataset if item.get(text_col)]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Character length\n",
    "        ax1.hist(text_lengths, bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "        ax1.set_xlabel('Text Length (characters)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Transcription Length Distribution (Characters)')\n",
    "        ax1.axvline(np.mean(text_lengths), color='r', linestyle='--', label=f'Mean: {np.mean(text_lengths):.1f}')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Word count\n",
    "        ax2.hist(word_counts, bins=50, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "        ax2.set_xlabel('Word Count')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title('Transcription Length Distribution (Words)')\n",
    "        ax2.axvline(np.mean(word_counts), color='r', linestyle='--', label=f'Mean: {np.mean(word_counts):.1f}')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir / \"text_length_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✓ Text length distribution chart saved\")\n",
    "    \n",
    "    # Summary statistics table\n",
    "    summary_data = []\n",
    "    if \"duration\" in dataset[0]:\n",
    "        durations = [item[\"duration\"] for item in dataset if item.get(\"duration\")]\n",
    "        summary_data.append(['Duration (sec)', f\"{np.mean(durations):.2f}\", f\"{np.median(durations):.2f}\", \n",
    "                            f\"{np.std(durations):.2f}\", f\"{np.min(durations):.2f}\", f\"{np.max(durations):.2f}\"])\n",
    "    \n",
    "    if text_col:\n",
    "        text_lengths = [len(item[text_col]) for item in dataset if item.get(text_col)]\n",
    "        summary_data.append(['Text Length (chars)', f\"{np.mean(text_lengths):.1f}\", f\"{np.median(text_lengths):.1f}\",\n",
    "                            f\"{np.std(text_lengths):.1f}\", f\"{np.min(text_lengths):.0f}\", f\"{np.max(text_lengths):.0f}\"])\n",
    "    \n",
    "    if summary_data:\n",
    "        summary_df = pd.DataFrame(summary_data, columns=['Metric', 'Mean', 'Median', 'Std', 'Min', 'Max'])\n",
    "        summary_df.to_csv(OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_data_summary.csv\", index=False)\n",
    "        print(\"✓ Data summary table saved\")\n",
    "\n",
    "# Create visualizations\n",
    "print(\"\\nCreating exploratory data analysis visualizations...\")\n",
    "create_eda_visualizations(dataset[\"train\"], validation_results, CHARTS_DIR)\n",
    "print(f\"\\nAll visualizations saved to: {CHARTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Splitting (No Data Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:34.462663Z",
     "iopub.status.busy": "2026-01-11T11:44:34.462287Z",
     "iopub.status.idle": "2026-01-11T11:44:34.558219Z",
     "shell.execute_reply": "2026-01-11T11:44:34.557773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Creating Data Splits\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split Sizes:\n",
      "  Train:         400 (80%)\n",
      "  Validation:     50 (10%)\n",
      "  Test:           50 (10%)\n",
      "  Total:         500\n",
      "\n",
      "✓ Split information saved to: outputs/whisper_azerbaijani_20260111_154331_split_info.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create Train/Val/Test Splits\n",
    "# ============================================================\n",
    "\n",
    "def create_splits(dataset: Dataset, config: Dict) -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Create stratified train/val/test splits with fixed random seed.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Input dataset\n",
    "        config: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        DatasetDict with train, validation, and test splits\n",
    "    \"\"\"\n",
    "    # Reset seed for reproducibility\n",
    "    set_seed(config[\"random_seed\"])\n",
    "    \n",
    "    train_ratio = config[\"train_ratio\"]\n",
    "    val_ratio = config[\"val_ratio\"]\n",
    "    test_ratio = config[\"test_ratio\"]\n",
    "    \n",
    "    # Validate ratios\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.0\"\n",
    "    \n",
    "    # First split: train and temp (val + test)\n",
    "    train_test_split = dataset.train_test_split(\n",
    "        test_size=(val_ratio + test_ratio),\n",
    "        seed=config[\"random_seed\"]\n",
    "    )\n",
    "    \n",
    "    # Second split: val and test from temp\n",
    "    val_test_ratio = test_ratio / (val_ratio + test_ratio)\n",
    "    val_test_split = train_test_split[\"test\"].train_test_split(\n",
    "        test_size=val_test_ratio,\n",
    "        seed=config[\"random_seed\"]\n",
    "    )\n",
    "    \n",
    "    splits = DatasetDict({\n",
    "        \"train\": train_test_split[\"train\"],\n",
    "        \"validation\": val_test_split[\"train\"],\n",
    "        \"test\": val_test_split[\"test\"],\n",
    "    })\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Create splits\n",
    "print(\"=\" * 70)\n",
    "print(\"Creating Data Splits\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "dataset_splits = create_splits(dataset[\"train\"], CONFIG)\n",
    "\n",
    "split_info = {\n",
    "    \"train\": len(dataset_splits[\"train\"]),\n",
    "    \"validation\": len(dataset_splits[\"validation\"]),\n",
    "    \"test\": len(dataset_splits[\"test\"]),\n",
    "    \"train_ratio\": CONFIG[\"train_ratio\"],\n",
    "    \"val_ratio\": CONFIG[\"val_ratio\"],\n",
    "    \"test_ratio\": CONFIG[\"test_ratio\"],\n",
    "    \"random_seed\": CONFIG[\"random_seed\"],\n",
    "}\n",
    "\n",
    "print(f\"\\nSplit Sizes:\")\n",
    "print(f\"  Train:      {split_info['train']:>6} ({CONFIG['train_ratio']*100:.0f}%)\")\n",
    "print(f\"  Validation: {split_info['validation']:>6} ({CONFIG['val_ratio']*100:.0f}%)\")\n",
    "print(f\"  Test:       {split_info['test']:>6} ({CONFIG['test_ratio']*100:.0f}%)\")\n",
    "print(f\"  Total:      {sum([split_info['train'], split_info['validation'], split_info['test']]):>6}\")\n",
    "\n",
    "# Save split info\n",
    "split_info_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_split_info.json\"\n",
    "with open(split_info_path, 'w') as f:\n",
    "    json.dump(split_info, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Split information saved to: {split_info_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:34.562140Z",
     "iopub.status.busy": "2026-01-11T11:44:34.561868Z",
     "iopub.status.idle": "2026-01-11T11:44:39.892438Z",
     "shell.execute_reply": "2026-01-11T11:44:39.890875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Loading Model: openai/whisper-tiny\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model loaded successfully\n",
      "Parameters: 37,760,640\n",
      "Vocabulary Size: 51,865\n",
      "Model Dimension: 384\n",
      "\n",
      "Model information saved to: outputs/whisper_azerbaijani_20260111_154331_model_info.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Load Whisper Model and Processor\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"Loading Model: {CONFIG['model_name']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load processor (combines tokenizer and feature extractor)\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    CONFIG[\"model_name\"],\n",
    "    language=CONFIG[\"language\"],\n",
    "    task=CONFIG[\"task\"]\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(CONFIG[\"model_name\"])\n",
    "\n",
    "# Configure model for Azerbaijani\n",
    "model.generation_config.language = CONFIG[\"language\"]\n",
    "model.generation_config.task = CONFIG[\"task\"]\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "\n",
    "# Model information\n",
    "model_info = {\n",
    "    \"model_name\": CONFIG[\"model_name\"],\n",
    "    \"num_parameters\": model.num_parameters(),\n",
    "    \"language\": CONFIG[\"language\"],\n",
    "    \"task\": CONFIG[\"task\"],\n",
    "    \"vocab_size\": model.config.vocab_size,\n",
    "    \"d_model\": model.config.d_model,\n",
    "}\n",
    "\n",
    "print(f\"\\n✓ Model loaded successfully\")\n",
    "print(f\"Parameters: {model_info['num_parameters']:,}\")\n",
    "print(f\"Vocabulary Size: {model_info['vocab_size']:,}\")\n",
    "print(f\"Model Dimension: {model_info['d_model']}\")\n",
    "\n",
    "# Save model info\n",
    "model_info_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_model_info.json\"\n",
    "with open(model_info_path, 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(f\"\\nModel information saved to: {model_info_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:39.952263Z",
     "iopub.status.busy": "2026-01-11T11:44:39.948621Z",
     "iopub.status.idle": "2026-01-11T11:44:52.881421Z",
     "shell.execute_reply": "2026-01-11T11:44:52.880839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Preprocessing Dataset\n",
      "======================================================================\n",
      "Audio column: audio\n",
      "Text column: text\n",
      "Target sampling rate: 16000 Hz\n",
      "\n",
      "Processing splits...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc7c80822a04f40acc808eccd6f80a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb336052241494390d3463877cc900b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f3caa244c546a2b78df17a8a770672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ All splits preprocessed\n",
      "  Train: 400 samples\n",
      "  Validation: 50 samples\n",
      "  Test: 50 samples\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Prepare Dataset for Training\n",
    "# ============================================================\n",
    "\n",
    "# Get column names from validation results\n",
    "audio_column = validation_results[\"audio_column\"]\n",
    "text_column = validation_results[\"text_column\"]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Preprocessing Dataset\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Audio column: {audio_column}\")\n",
    "print(f\"Text column: {text_column}\")\n",
    "print(f\"Target sampling rate: {CONFIG['sampling_rate']} Hz\")\n",
    "\n",
    "# Cast audio to correct sampling rate\n",
    "dataset_splits = dataset_splits.cast_column(\n",
    "    audio_column,\n",
    "    Audio(sampling_rate=CONFIG[\"sampling_rate\"])\n",
    ")\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    \"\"\"\n",
    "    Prepare a batch for training.\n",
    "    Converts audio to features and tokenizes text.\n",
    "    \"\"\"\n",
    "    # Extract audio\n",
    "    audio = batch[audio_column]\n",
    "    \n",
    "    # Compute input features\n",
    "    batch[\"input_features\"] = processor.feature_extractor(\n",
    "        audio[\"array\"],\n",
    "        sampling_rate=audio[\"sampling_rate\"]\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # Tokenize text\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[text_column]).input_ids\n",
    "    \n",
    "    return batch\n",
    "\n",
    "# Process all splits\n",
    "print(\"\\nProcessing splits...\")\n",
    "processed_datasets = dataset_splits.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=dataset_splits[\"train\"].column_names,\n",
    "    desc=\"Preprocessing\",\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ All splits preprocessed\")\n",
    "print(f\"  Train: {len(processed_datasets['train'])} samples\")\n",
    "print(f\"  Validation: {len(processed_datasets['validation'])} samples\")\n",
    "print(f\"  Test: {len(processed_datasets['test'])} samples\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:52.890230Z",
     "iopub.status.busy": "2026-01-11T11:44:52.889900Z",
     "iopub.status.idle": "2026-01-11T11:44:52.925990Z",
     "shell.execute_reply": "2026-01-11T11:44:52.925666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data collator created\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Data Collator for Dynamic Padding\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs and labels.\n",
    "    \"\"\"\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        features: List[Dict[str, torch.Tensor]]\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # Split inputs and labels\n",
    "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "\n",
    "        # Pad input features\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Pad labels\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Replace padding with -100 to ignore in loss computation\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1),\n",
    "            -100\n",
    "        )\n",
    "\n",
    "        # Remove BOS token if present\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "# Create data collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")\n",
    "\n",
    "print(\"✓ Data collator created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:52.932552Z",
     "iopub.status.busy": "2026-01-11T11:44:52.932348Z",
     "iopub.status.idle": "2026-01-11T11:44:55.594076Z",
     "shell.execute_reply": "2026-01-11T11:44:55.590439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation metrics configured\n",
      "  Metric: Word Error Rate (WER)\n",
      "  Lower is better (0% = perfect transcription)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Define Evaluation Metrics\n",
    "# ============================================================\n",
    "\n",
    "# Load WER metric\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute Word Error Rate (WER) during evaluation.\n",
    "    \n",
    "    Lower WER is better (0% is perfect).\n",
    "    \"\"\"\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # Replace -100 with pad token\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # Decode predictions and labels\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Compute WER\n",
    "    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "print(\"✓ Evaluation metrics configured\")\n",
    "print(\"  Metric: Word Error Rate (WER)\")\n",
    "print(\"  Lower is better (0% = perfect transcription)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:55.654471Z",
     "iopub.status.busy": "2026-01-11T11:44:55.652716Z",
     "iopub.status.idle": "2026-01-11T11:44:55.946896Z",
     "shell.execute_reply": "2026-01-11T11:44:55.939159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Training Configuration\n",
      "======================================================================\n",
      "Output directory: artifacts/whisper_azerbaijani_20260111_154331\n",
      "\n",
      "Hyperparameters:\n",
      "  Batch size: 4\n",
      "  Gradient accumulation: 2\n",
      "  Effective batch size: 8\n",
      "  Learning rate: 1e-05\n",
      "  Epochs: 1\n",
      "  Max steps: 100\n",
      "  Warmup steps: 20\n",
      "  FP16: False\n",
      "\n",
      "Evaluation:\n",
      "  Eval every: 50 steps\n",
      "  Save every: 50 steps\n",
      "  Keep best: 3 checkpoints\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Training Arguments\n",
    "# ============================================================\n",
    "\n",
    "# Create output directory for this experiment\n",
    "experiment_artifacts_dir = ARTIFACTS_DIR / CONFIG[\"experiment_name\"]\n",
    "experiment_artifacts_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=str(experiment_artifacts_dir),\n",
    "    \n",
    "    # Training parameters\n",
    "    per_device_train_batch_size=CONFIG[\"batch_size\"],\n",
    "    per_device_eval_batch_size=CONFIG[\"batch_size\"],\n",
    "    gradient_accumulation_steps=CONFIG[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    num_train_epochs=CONFIG[\"num_epochs\"],\n",
    "    max_steps=CONFIG[\"max_steps\"],\n",
    "    warmup_steps=CONFIG[\"warmup_steps\"],\n",
    "    \n",
    "    # Precision\n",
    "    fp16=CONFIG[\"fp16\"],\n",
    "    \n",
    "    # Evaluation and saving\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=CONFIG[\"eval_steps\"],\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=CONFIG[\"save_steps\"],\n",
    "    save_total_limit=CONFIG[\"save_total_limit\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    \n",
    "    # Generation settings for evaluation\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=CONFIG[\"logging_steps\"],\n",
    "    logging_dir=str(experiment_artifacts_dir / \"logs\"),\n",
    "    report_to=[\"tensorboard\"],\n",
    "    \n",
    "    # Device\n",
    "    use_cpu=(device_info[\"device\"] == \"cpu\"),\n",
    "    \n",
    "    # Reproducibility\n",
    "    seed=CONFIG[\"random_seed\"],\n",
    "    data_seed=CONFIG[\"random_seed\"],\n",
    "    \n",
    "    # Misc\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Training Configuration\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Output directory: {experiment_artifacts_dir}\")\n",
    "print(f\"\\nHyperparameters:\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Gradient accumulation: {CONFIG['gradient_accumulation_steps']}\")\n",
    "print(f\"  Effective batch size: {CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']}\")\n",
    "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"  Max steps: {CONFIG['max_steps'] if CONFIG['max_steps'] > 0 else 'Full epochs'}\")\n",
    "print(f\"  Warmup steps: {CONFIG['warmup_steps']}\")\n",
    "print(f\"  FP16: {CONFIG['fp16']}\")\n",
    "print(f\"\\nEvaluation:\")\n",
    "print(f\"  Eval every: {CONFIG['eval_steps']} steps\")\n",
    "print(f\"  Save every: {CONFIG['save_steps']} steps\")\n",
    "print(f\"  Keep best: {CONFIG['save_total_limit']} checkpoints\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:55.982295Z",
     "iopub.status.busy": "2026-01-11T11:44:55.980378Z",
     "iopub.status.idle": "2026-01-11T11:44:56.032542Z",
     "shell.execute_reply": "2026-01-11T11:44:56.026464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training metrics callback created\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Custom Callback for Tracking Training Progress\n",
    "# ============================================================\n",
    "\n",
    "class TrainingMetricsCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Callback to track and save training metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dir: Path):\n",
    "        self.output_dir = output_dir\n",
    "        self.training_history = []\n",
    "        self.eval_history = []\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs:\n",
    "            logs_copy = logs.copy()\n",
    "            logs_copy[\"step\"] = state.global_step\n",
    "            logs_copy[\"epoch\"] = state.epoch\n",
    "            \n",
    "            if \"loss\" in logs:\n",
    "                self.training_history.append(logs_copy)\n",
    "            if \"eval_wer\" in logs:\n",
    "                self.eval_history.append(logs_copy)\n",
    "    \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        # Save training history\n",
    "        if self.training_history:\n",
    "            train_df = pd.DataFrame(self.training_history)\n",
    "            train_df.to_csv(\n",
    "                self.output_dir / f\"{CONFIG['experiment_name']}_training_history.csv\",\n",
    "                index=False\n",
    "            )\n",
    "        \n",
    "        # Save evaluation history\n",
    "        if self.eval_history:\n",
    "            eval_df = pd.DataFrame(self.eval_history)\n",
    "            eval_df.to_csv(\n",
    "                self.output_dir / f\"{CONFIG['experiment_name']}_eval_history.csv\",\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "# Create callback\n",
    "metrics_callback = TrainingMetricsCallback(OUTPUTS_DIR)\n",
    "\n",
    "print(\"✓ Training metrics callback created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:56.047298Z",
     "iopub.status.busy": "2026-01-11T11:44:56.045908Z",
     "iopub.status.idle": "2026-01-11T11:44:58.263451Z",
     "shell.execute_reply": "2026-01-11T11:44:58.262488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trainer initialized\n",
      "  Train samples: 400\n",
      "  Validation samples: 50\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Initialize Trainer\n",
    "# ============================================================\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_datasets[\"train\"],\n",
    "    eval_dataset=processed_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=processor.feature_extractor,\n",
    "    callbacks=[metrics_callback],\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer initialized\")\n",
    "print(f\"  Train samples: {len(processed_datasets['train'])}\")\n",
    "print(f\"  Validation samples: {len(processed_datasets['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T11:44:58.269605Z",
     "iopub.status.busy": "2026-01-11T11:44:58.269399Z",
     "iopub.status.idle": "2026-01-11T16:45:29.542107Z",
     "shell.execute_reply": "2026-01-11T16:45:29.539111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Starting Training\n",
      "======================================================================\n",
      "Device: Apple Silicon (MPS)\n",
      "Mode: SAMPLE\n",
      "\n",
      "This may take a while...\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismatsamadov/.pyenv/versions/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 4:59:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.385900</td>\n",
       "      <td>1.335438</td>\n",
       "      <td>66.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>1.129975</td>\n",
       "      <td>59.696970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismatsamadov/.pyenv/versions/myenv/lib/python3.10/site-packages/transformers/modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismatsamadov/.pyenv/versions/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Training Completed!\n",
      "======================================================================\n",
      "\n",
      "Training Summary:\n",
      "  Runtime: 18029.75 seconds\n",
      "  Samples/second: 0.04\n",
      "  Final loss: 1.7833\n",
      "  Epochs completed: 2.00\n",
      "\n",
      "Training metrics saved to: outputs/whisper_azerbaijani_20260111_154331_training_metrics.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Train Model\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Starting Training\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Device: {device_info['device_name']}\")\n",
    "print(f\"Mode: {'SAMPLE' if CONFIG['sample_mode'] else 'FULL'}\")\n",
    "print(\"\\nThis may take a while...\")\n",
    "print(\"=\" * 70 + \"\\n\")\n",
    "\n",
    "# Train\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Training Completed!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save training metrics\n",
    "training_metrics = {\n",
    "    \"train_runtime\": train_result.metrics.get(\"train_runtime\", 0),\n",
    "    \"train_samples_per_second\": train_result.metrics.get(\"train_samples_per_second\", 0),\n",
    "    \"train_steps_per_second\": train_result.metrics.get(\"train_steps_per_second\", 0),\n",
    "    \"total_flos\": train_result.metrics.get(\"total_flos\", 0),\n",
    "    \"train_loss\": train_result.metrics.get(\"train_loss\", 0),\n",
    "    \"epoch\": train_result.metrics.get(\"epoch\", 0),\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Runtime: {training_metrics['train_runtime']:.2f} seconds\")\n",
    "print(f\"  Samples/second: {training_metrics['train_samples_per_second']:.2f}\")\n",
    "print(f\"  Final loss: {training_metrics['train_loss']:.4f}\")\n",
    "print(f\"  Epochs completed: {training_metrics['epoch']:.2f}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_training_metrics.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(training_metrics, f, indent=2)\n",
    "\n",
    "print(f\"\\nTraining metrics saved to: {metrics_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:45:29.567351Z",
     "iopub.status.busy": "2026-01-11T16:45:29.566866Z",
     "iopub.status.idle": "2026-01-11T16:45:46.719837Z",
     "shell.execute_reply": "2026-01-11T16:45:46.719270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Evaluating on Validation Set\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismatsamadov/.pyenv/versions/myenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "  eval_loss: 1.1300\n",
      "  eval_wer: 59.6970\n",
      "  eval_runtime: 17.1248\n",
      "  eval_samples_per_second: 2.9200\n",
      "  eval_steps_per_second: 0.7590\n",
      "  epoch: 2.0000\n",
      "\n",
      "Validation results saved to: outputs/whisper_azerbaijani_20260111_154331_validation_results.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluate on Validation Set\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Evaluating on Validation Set\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "val_results = trainer.evaluate()\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "for key, value in val_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save results\n",
    "val_results_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_validation_results.json\"\n",
    "with open(val_results_path, 'w') as f:\n",
    "    json.dump(val_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nValidation results saved to: {val_results_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:45:46.722920Z",
     "iopub.status.busy": "2026-01-11T16:45:46.722754Z",
     "iopub.status.idle": "2026-01-11T16:46:03.775273Z",
     "shell.execute_reply": "2026-01-11T16:46:03.774327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Evaluating on Test Set (Hold-out)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "  eval_loss: 1.2400\n",
      "  eval_wer: 59.2793\n",
      "  eval_runtime: 17.0358\n",
      "  eval_samples_per_second: 2.9350\n",
      "  eval_steps_per_second: 0.7630\n",
      "  epoch: 2.0000\n",
      "\n",
      "Test results saved to: outputs/whisper_azerbaijani_20260111_154331_test_results.json\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Evaluate on Test Set (Final Evaluation)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Evaluating on Test Set (Hold-out)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_results = trainer.evaluate(processed_datasets[\"test\"])\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "for key, value in test_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save results\n",
    "test_results_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_test_results.json\"\n",
    "with open(test_results_path, 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(f\"\\nTest results saved to: {test_results_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:46:03.779274Z",
     "iopub.status.busy": "2026-01-11T16:46:03.778844Z",
     "iopub.status.idle": "2026-01-11T16:46:07.608886Z",
     "shell.execute_reply": "2026-01-11T16:46:07.608374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Sample Predictions\n",
      "======================================================================\n",
      "\n",
      "Sample 1:\n",
      "  Reference:  Biz dəyişənə STR funksiyasını təyin edərək bu funksiyanın qaytardığı dəyəri həmin dəyişənə dəyər kimi təyin edə bilərik.\n",
      "  Prediction:  Biz dəyxəna əstir funksiyasın təyini dəriq bu funksiyanın qətardığı dəyəriyə həmin dəyxəna dəyərqimi təyini də bilərik.\n",
      "\n",
      "Sample 2:\n",
      "  Reference:  İndi elə təsəvvür edək ki, simvolların sayını bilmədiyimiz sözün sonuncu simvolunu əldə etməyi bizə tapşırıblar.\n",
      "  Prediction:  Ində elə təsəvvur edək ki, simvulları sayını bilmədiyimiz sözün sonuncu simvulunu əldə etməyi bizə tapşırıqları.\n",
      "\n",
      "Sample 3:\n",
      "  Reference:  Bu mövzumuzda biz string tipli, yəni sətr tipli obyektlər haqqında ətraflı məlumat əldə edəcəyik.\n",
      "  Prediction:  Bu müvzimiz də biz strengç tipli, yəni sətr tipli obyəqlər həqqında ətrəfləlmaq əldə dəcəyik.\n",
      "\n",
      "Sample 4:\n",
      "  Reference:  Tam bölmə əməliyyatı icra edərkən Python bizə bir ədədi digər ədədinə böləndə aldığımız nəticəsinin yalnız tam hissəsini bizə qaytarır.\n",
      "  Prediction:  Tam bölmə əməliyyatı izra edəxən Python bizə bir ədədi dədir ədədini, böləndə aldığımız nəxdiyicexinin yalnız tam hissəsini bizə qəyitarır.\n",
      "\n",
      "Sample 5:\n",
      "  Reference:  Gəlin biz dərsimizi konsul yox, fayl vasitəsilə davam etdirək.\n",
      "  Prediction:  Gənin biz dərsimizə konsol yox, falvası sila davam ettirəq.\n",
      "\n",
      "All sample predictions saved to: outputs/whisper_azerbaijani_20260111_154331_sample_predictions.csv\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Generate Sample Predictions\n",
    "# ============================================================\n",
    "\n",
    "def generate_sample_predictions(\n",
    "    trainer: Seq2SeqTrainer,\n",
    "    dataset: Dataset,\n",
    "    processor: WhisperProcessor,\n",
    "    n_samples: int = 10\n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate predictions for sample test cases.\n",
    "    \"\"\"\n",
    "    # Get random samples\n",
    "    indices = random.sample(range(len(dataset)), min(n_samples, len(dataset)))\n",
    "    samples = dataset.select(indices)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = trainer.predict(samples)\n",
    "    pred_ids = predictions.predictions\n",
    "    label_ids = predictions.label_ids\n",
    "    \n",
    "    # Decode\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Create results\n",
    "    results = []\n",
    "    for i, (pred, label) in enumerate(zip(pred_str, label_str)):\n",
    "        results.append({\n",
    "            \"sample_id\": i + 1,\n",
    "            \"reference\": label,\n",
    "            \"prediction\": pred,\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Generating sample predictions...\")\n",
    "sample_predictions = generate_sample_predictions(\n",
    "    trainer,\n",
    "    processed_datasets[\"test\"],\n",
    "    processor,\n",
    "    n_samples=10\n",
    ")\n",
    "\n",
    "# Display samples\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Sample Predictions\")\n",
    "print(\"=\" * 70)\n",
    "for sample in sample_predictions[:5]:  # Show first 5\n",
    "    print(f\"\\nSample {sample['sample_id']}:\")\n",
    "    print(f\"  Reference:  {sample['reference']}\")\n",
    "    print(f\"  Prediction: {sample['prediction']}\")\n",
    "\n",
    "# Save all predictions\n",
    "predictions_df = pd.DataFrame(sample_predictions)\n",
    "predictions_path = OUTPUTS_DIR / f\"{CONFIG['experiment_name']}_sample_predictions.csv\"\n",
    "predictions_df.to_csv(predictions_path, index=False)\n",
    "\n",
    "print(f\"\\nAll sample predictions saved to: {predictions_path}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Training Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:46:07.613153Z",
     "iopub.status.busy": "2026-01-11T16:46:07.612903Z",
     "iopub.status.idle": "2026-01-11T16:46:09.906237Z",
     "shell.execute_reply": "2026-01-11T16:46:09.905612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating training visualizations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training loss curve saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Validation WER curve saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training overview saved\n",
      "\n",
      "All charts saved to: charts\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create Training Visualizations\n",
    "# ============================================================\n",
    "\n",
    "def plot_training_curves(metrics_callback: TrainingMetricsCallback, save_dir: Path):\n",
    "    \"\"\"\n",
    "    Create comprehensive training visualization plots.\n",
    "    \"\"\"\n",
    "    if not metrics_callback.training_history:\n",
    "        print(\"No training history available for plotting\")\n",
    "        return\n",
    "    \n",
    "    # Convert to dataframes\n",
    "    train_df = pd.DataFrame(metrics_callback.training_history)\n",
    "    eval_df = pd.DataFrame(metrics_callback.eval_history) if metrics_callback.eval_history else None\n",
    "    \n",
    "    # Training loss curve\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.plot(train_df['step'], train_df['loss'], label='Training Loss', linewidth=2)\n",
    "    ax.set_xlabel('Training Steps')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training Loss Over Time')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"training_loss_curve.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Training loss curve saved\")\n",
    "    \n",
    "    # Evaluation WER curve\n",
    "    if eval_df is not None and not eval_df.empty:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(eval_df['step'], eval_df['eval_wer'], label='Validation WER', \n",
    "                color='orange', linewidth=2, marker='o')\n",
    "        ax.set_xlabel('Training Steps')\n",
    "        ax.set_ylabel('Word Error Rate (%)')\n",
    "        ax.set_title('Validation WER Over Time (Lower is Better)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir / \"validation_wer_curve.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✓ Validation WER curve saved\")\n",
    "    \n",
    "    # Combined plot\n",
    "    if eval_df is not None and not eval_df.empty:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Loss\n",
    "        ax1.plot(train_df['step'], train_df['loss'], linewidth=2)\n",
    "        ax1.set_xlabel('Training Steps')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Training Loss')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # WER\n",
    "        ax2.plot(eval_df['step'], eval_df['eval_wer'], color='orange', \n",
    "                linewidth=2, marker='o', markersize=4)\n",
    "        ax2.set_xlabel('Training Steps')\n",
    "        ax2.set_ylabel('Word Error Rate (%)')\n",
    "        ax2.set_title('Validation WER')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_dir / \"training_overview.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"✓ Training overview saved\")\n",
    "\n",
    "# Create plots\n",
    "print(\"\\nCreating training visualizations...\")\n",
    "plot_training_curves(metrics_callback, CHARTS_DIR)\n",
    "print(f\"\\nAll charts saved to: {CHARTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:46:09.909192Z",
     "iopub.status.busy": "2026-01-11T16:46:09.909008Z",
     "iopub.status.idle": "2026-01-11T16:46:11.190067Z",
     "shell.execute_reply": "2026-01-11T16:46:11.189757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating results summary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Results summary visualization saved\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create Final Results Summary Visualization\n",
    "# ============================================================\n",
    "\n",
    "def create_results_summary(train_metrics, val_results, test_results, save_dir: Path):\n",
    "    \"\"\"\n",
    "    Create a comprehensive results summary visualization.\n",
    "    \"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. WER Comparison\n",
    "    wer_data = {\n",
    "        'Validation': val_results.get('eval_wer', 0),\n",
    "        'Test': test_results.get('eval_wer', 0),\n",
    "    }\n",
    "    ax1.bar(wer_data.keys(), wer_data.values(), color=['#2ecc71', '#e74c3c'])\n",
    "    ax1.set_ylabel('Word Error Rate (%)')\n",
    "    ax1.set_title('Model Performance (Lower is Better)')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    for i, (k, v) in enumerate(wer_data.items()):\n",
    "        ax1.text(i, v + 0.5, f'{v:.2f}%', ha='center', fontweight='bold')\n",
    "    \n",
    "    # 2. Training Time Breakdown\n",
    "    runtime_hours = train_metrics['train_runtime'] / 3600\n",
    "    ax2.bar(['Training Time'], [runtime_hours], color='#3498db')\n",
    "    ax2.set_ylabel('Hours')\n",
    "    ax2.set_title('Training Duration')\n",
    "    ax2.text(0, runtime_hours + runtime_hours*0.05, f'{runtime_hours:.2f}h', \n",
    "            ha='center', fontweight='bold')\n",
    "    \n",
    "    # 3. Dataset Split Sizes\n",
    "    split_sizes = {\n",
    "        'Train': len(processed_datasets['train']),\n",
    "        'Validation': len(processed_datasets['validation']),\n",
    "        'Test': len(processed_datasets['test']),\n",
    "    }\n",
    "    ax3.bar(split_sizes.keys(), split_sizes.values(), color=['#9b59b6', '#f39c12', '#1abc9c'])\n",
    "    ax3.set_ylabel('Number of Samples')\n",
    "    ax3.set_title('Dataset Split Sizes')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Training Metrics Summary\n",
    "    metrics_text = f\"\"\"\n",
    "    Experiment: {CONFIG['experiment_name']}\n",
    "    \n",
    "    Model: {CONFIG['model_name']}\n",
    "    Parameters: {model_info['num_parameters']:,}\n",
    "    \n",
    "    Training:\n",
    "    - Epochs: {train_metrics['epoch']:.2f}\n",
    "    - Final Loss: {train_metrics['train_loss']:.4f}\n",
    "    - Samples/sec: {train_metrics['train_samples_per_second']:.2f}\n",
    "    \n",
    "    Validation WER: {val_results.get('eval_wer', 0):.2f}%\n",
    "    Test WER: {test_results.get('eval_wer', 0):.2f}%\n",
    "    \n",
    "    Device: {device_info['device_name']}\n",
    "    FP16: {CONFIG['fp16']}\n",
    "    Batch Size: {CONFIG['batch_size']}\n",
    "    Learning Rate: {CONFIG['learning_rate']}\n",
    "    \"\"\"\n",
    "    ax4.text(0.1, 0.5, metrics_text, fontsize=10, verticalalignment='center',\n",
    "            fontfamily='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    ax4.axis('off')\n",
    "    ax4.set_title('Training Summary')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"results_summary.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"✓ Results summary visualization saved\")\n",
    "\n",
    "# Create summary\n",
    "print(\"\\nCreating results summary...\")\n",
    "create_results_summary(training_metrics, val_results, test_results, CHARTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:46:11.192027Z",
     "iopub.status.busy": "2026-01-11T16:46:11.191884Z",
     "iopub.status.idle": "2026-01-11T16:46:11.541538Z",
     "shell.execute_reply": "2026-01-11T16:46:11.541217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Saving Model Artifacts\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model saved to: artifacts/whisper_azerbaijani_20260111_154331_final\n",
      "✓ Experiment metadata saved to: artifacts/whisper_azerbaijani_20260111_154331_final/experiment_metadata.json\n",
      "✓ Model README saved to: artifacts/whisper_azerbaijani_20260111_154331_final/README.md\n",
      "\n",
      "======================================================================\n",
      "All artifacts saved successfully!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Save Final Model and Artifacts\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Saving Model Artifacts\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create final model directory\n",
    "final_model_dir = ARTIFACTS_DIR / f\"{CONFIG['experiment_name']}_final\"\n",
    "final_model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save model and processor\n",
    "trainer.save_model(str(final_model_dir))\n",
    "processor.save_pretrained(str(final_model_dir))\n",
    "\n",
    "print(f\"\\n✓ Model saved to: {final_model_dir}\")\n",
    "\n",
    "# Save complete experiment metadata\n",
    "experiment_metadata = {\n",
    "    \"experiment_name\": CONFIG[\"experiment_name\"],\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"config\": CONFIG,\n",
    "    \"device_info\": device_info,\n",
    "    \"model_info\": model_info,\n",
    "    \"split_info\": split_info,\n",
    "    \"training_metrics\": training_metrics,\n",
    "    \"validation_results\": val_results,\n",
    "    \"test_results\": test_results,\n",
    "    \"model_path\": str(final_model_dir),\n",
    "}\n",
    "\n",
    "metadata_path = final_model_dir / \"experiment_metadata.json\"\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(experiment_metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Experiment metadata saved to: {metadata_path}\")\n",
    "\n",
    "# Create README for the model\n",
    "readme_content = f\"\"\"# Azerbaijani ASR Model\n",
    "\n",
    "## Experiment: {CONFIG['experiment_name']}\n",
    "\n",
    "### Model Information\n",
    "- Base Model: {CONFIG['model_name']}\n",
    "- Language: {CONFIG['language']}\n",
    "- Task: {CONFIG['task']}\n",
    "- Parameters: {model_info['num_parameters']:,}\n",
    "\n",
    "### Performance\n",
    "- Validation WER: {val_results.get('eval_wer', 0):.2f}%\n",
    "- Test WER: {test_results.get('eval_wer', 0):.2f}%\n",
    "\n",
    "### Training Details\n",
    "- Training Samples: {split_info['train']}\n",
    "- Validation Samples: {split_info['validation']}\n",
    "- Test Samples: {split_info['test']}\n",
    "- Epochs: {training_metrics['epoch']:.2f}\n",
    "- Training Time: {training_metrics['train_runtime']/3600:.2f} hours\n",
    "- Device: {device_info['device_name']}\n",
    "\n",
    "### Usage\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the model\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"{final_model_dir}\"\n",
    ")\n",
    "\n",
    "# Transcribe audio\n",
    "result = pipe(\"path/to/audio.wav\")\n",
    "print(result[\"text\"])\n",
    "```\n",
    "\n",
    "### Files\n",
    "- `config.json` - Model configuration\n",
    "- `preprocessor_config.json` - Audio preprocessing config\n",
    "- `tokenizer_config.json` - Tokenizer configuration\n",
    "- `model.safetensors` - Model weights\n",
    "- `experiment_metadata.json` - Complete experiment details\n",
    "\n",
    "### Reproducibility\n",
    "- Random Seed: {CONFIG['random_seed']}\n",
    "- All configuration and results saved in experiment_metadata.json\n",
    "\n",
    "Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "readme_path = final_model_dir / \"README.md\"\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(f\"✓ Model README saved to: {readme_path}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"All artifacts saved successfully!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:46:11.543796Z",
     "iopub.status.busy": "2026-01-11T16:46:11.543674Z",
     "iopub.status.idle": "2026-01-11T16:46:11.881367Z",
     "shell.execute_reply": "2026-01-11T16:46:11.881009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Testing Inference Pipeline\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Inference pipeline loaded successfully\n",
      "  Model: artifacts/whisper_azerbaijani_20260111_154331_final\n",
      "  Device: mps\n",
      "\n",
      "To use the model for inference:\n",
      "\n",
      "```python\n",
      "from transformers import pipeline\n",
      "\n",
      "# Load the model\n",
      "pipe = pipeline(\n",
      "    \"automatic-speech-recognition\",\n",
      "    model=\"artifacts/whisper_azerbaijani_20260111_154331_final\"\n",
      ")\n",
      "\n",
      "# Transcribe audio file\n",
      "result = pipe(\"path/to/audio.wav\")\n",
      "print(result[\"text\"])\n",
      "\n",
      "# Or with audio array\n",
      "import librosa\n",
      "audio, sr = librosa.load(\"path/to/audio.wav\", sr=16000)\n",
      "result = pipe(audio)\n",
      "print(result[\"text\"])\n",
      "```\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Test Inference Pipeline\n",
    "# ============================================================\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Testing Inference Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Load inference pipeline\n",
    "device_id = 0 if device_info[\"device\"] == \"cuda\" else -1\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=str(final_model_dir),\n",
    "    device=device_id,\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Inference pipeline loaded successfully\")\n",
    "print(f\"  Model: {final_model_dir}\")\n",
    "print(f\"  Device: {device_info['device']}\")\n",
    "\n",
    "print(\"\\nTo use the model for inference:\")\n",
    "print(\"\"\"\\n```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the model\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"{}\"\n",
    ")\n",
    "\n",
    "# Transcribe audio file\n",
    "result = pipe(\"path/to/audio.wav\")\n",
    "print(result[\"text\"])\n",
    "\n",
    "# Or with audio array\n",
    "import librosa\n",
    "audio, sr = librosa.load(\"path/to/audio.wav\", sr=16000)\n",
    "result = pipe(audio)\n",
    "print(result[\"text\"])\n",
    "```\"\"\".format(final_model_dir))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-11T16:46:11.883322Z",
     "iopub.status.busy": "2026-01-11T16:46:11.883192Z",
     "iopub.status.idle": "2026-01-11T16:46:11.891262Z",
     "shell.execute_reply": "2026-01-11T16:46:11.890980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL EXPERIMENT SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Experiment: whisper_azerbaijani_20260111_154331\n",
      "Completed: 2026-01-11 20:46:11\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "MODEL PERFORMANCE\n",
      "----------------------------------------------------------------------\n",
      "Validation WER: 59.70%\n",
      "Test WER: 59.28%\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DATASET\n",
      "----------------------------------------------------------------------\n",
      "Train: 400 samples\n",
      "Validation: 50 samples\n",
      "Test: 50 samples\n",
      "Total: 500 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING\n",
      "----------------------------------------------------------------------\n",
      "Runtime: 5.01 hours\n",
      "Epochs: 2.00\n",
      "Final Loss: 1.7833\n",
      "Throughput: 0.04 samples/sec\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "ARTIFACTS LOCATIONS\n",
      "----------------------------------------------------------------------\n",
      "Model: artifacts/whisper_azerbaijani_20260111_154331_final\n",
      "Charts: charts\n",
      "Outputs: outputs\n",
      "All Artifacts: artifacts\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GENERATED FILES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Charts:\n",
      "  - duration_distribution.png\n",
      "  - results_summary.png\n",
      "  - text_length_distribution.png\n",
      "  - training_loss_curve.png\n",
      "  - training_overview.png\n",
      "  - validation_wer_curve.png\n",
      "\n",
      "Outputs:\n",
      "  - whisper_azerbaijani_20260111_154331_config.json\n",
      "  - whisper_azerbaijani_20260111_154331_data_summary.csv\n",
      "  - whisper_azerbaijani_20260111_154331_device_info.json\n",
      "  - whisper_azerbaijani_20260111_154331_eval_history.csv\n",
      "  - whisper_azerbaijani_20260111_154331_model_info.json\n",
      "  - whisper_azerbaijani_20260111_154331_sample_predictions.csv\n",
      "  - whisper_azerbaijani_20260111_154331_split_info.json\n",
      "  - whisper_azerbaijani_20260111_154331_test_results.json\n",
      "  - whisper_azerbaijani_20260111_154331_training_history.csv\n",
      "  - whisper_azerbaijani_20260111_154331_training_metrics.json\n",
      "  - whisper_azerbaijani_20260111_154331_validation.json\n",
      "  - whisper_azerbaijani_20260111_154331_validation_results.json\n",
      "\n",
      "Model Files:\n",
      "  - README.md (0.00 MB)\n",
      "  - added_tokens.json (0.03 MB)\n",
      "  - config.json (0.00 MB)\n",
      "  - experiment_metadata.json (0.00 MB)\n",
      "  - generation_config.json (0.00 MB)\n",
      "  - merges.txt (0.47 MB)\n",
      "  - model.safetensors (144.06 MB)\n",
      "  - normalizer.json (0.05 MB)\n",
      "  - preprocessor_config.json (0.00 MB)\n",
      "  - special_tokens_map.json (0.00 MB)\n",
      "  - tokenizer.json (3.75 MB)\n",
      "  - tokenizer_config.json (0.27 MB)\n",
      "  - training_args.bin (0.01 MB)\n",
      "  - vocab.json (0.80 MB)\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENT COMPLETED SUCCESSFULLY\n",
      "======================================================================\n",
      "\n",
      "✓ All stages completed\n",
      "✓ Model trained and evaluated\n",
      "✓ All artifacts saved\n",
      "✓ Visualizations generated\n",
      "✓ Results documented\n",
      "\n",
      "Next steps:\n",
      "  1. Review visualizations in the charts/ directory\n",
      "  2. Examine detailed metrics in the outputs/ directory\n",
      "  3. Load the model from artifacts/ for inference\n",
      "  4. For full training, set SAMPLE_MODE=False and rerun\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Generate Final Report\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL EXPERIMENT SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nExperiment: {CONFIG['experiment_name']}\")\n",
    "print(f\"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Validation WER: {val_results.get('eval_wer', 0):.2f}%\")\n",
    "print(f\"Test WER: {test_results.get('eval_wer', 0):.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"DATASET\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Train: {split_info['train']} samples\")\n",
    "print(f\"Validation: {split_info['validation']} samples\")\n",
    "print(f\"Test: {split_info['test']} samples\")\n",
    "print(f\"Total: {sum([split_info['train'], split_info['validation'], split_info['test']])} samples\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TRAINING\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Runtime: {training_metrics['train_runtime']/3600:.2f} hours\")\n",
    "print(f\"Epochs: {training_metrics['epoch']:.2f}\")\n",
    "print(f\"Final Loss: {training_metrics['train_loss']:.4f}\")\n",
    "print(f\"Throughput: {training_metrics['train_samples_per_second']:.2f} samples/sec\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"ARTIFACTS LOCATIONS\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Model: {final_model_dir}\")\n",
    "print(f\"Charts: {CHARTS_DIR}\")\n",
    "print(f\"Outputs: {OUTPUTS_DIR}\")\n",
    "print(f\"All Artifacts: {ARTIFACTS_DIR}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"GENERATED FILES\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# List all generated files\n",
    "print(\"\\nCharts:\")\n",
    "for f in sorted(CHARTS_DIR.glob(\"*.png\")):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nOutputs:\")\n",
    "for f in sorted(OUTPUTS_DIR.glob(f\"{CONFIG['experiment_name']}*\")):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "print(\"\\nModel Files:\")\n",
    "for f in sorted(final_model_dir.glob(\"*\")):\n",
    "    if f.is_file():\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  - {f.name} ({size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPERIMENT COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n✓ All stages completed\")\n",
    "print(\"✓ Model trained and evaluated\")\n",
    "print(\"✓ All artifacts saved\")\n",
    "print(\"✓ Visualizations generated\")\n",
    "print(\"✓ Results documented\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Review visualizations in the charts/ directory\")\n",
    "print(\"  2. Examine detailed metrics in the outputs/ directory\")\n",
    "print(\"  3. Load the model from artifacts/ for inference\")\n",
    "print(\"  4. For full training, set SAMPLE_MODE=False and rerun\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08338bfbcb024bec994b81a310147a61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1120785e1f51468b902bc044d2823f1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "13fa9348ab99465c863f291cc97419f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b0201c4497541f69437fc9d9f61d369": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_32a7c817e60c4f4aaa7c513ed82f6c02",
       "placeholder": "​",
       "style": "IPY_MODEL_683e8d8700ca40c3bc61712737621211",
       "tabbable": null,
       "tooltip": null,
       "value": " 50/50 [00:00&lt;00:00, 70.52 examples/s]"
      }
     },
     "21ce0462fd334388afbc784426f24e2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "23bb17b978414f40af702999478deb65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2b251e61d28e43dcbb06480903e66af8",
       "placeholder": "​",
       "style": "IPY_MODEL_44133978abc846f2b1b32cce17ce28ba",
       "tabbable": null,
       "tooltip": null,
       "value": " 133/133 [00:01&lt;00:00,  6.52it/s]"
      }
     },
     "2b251e61d28e43dcbb06480903e66af8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "324c7eb3ff924539b36200072c65ef46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_13fa9348ab99465c863f291cc97419f9",
       "max": 400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d588b03408448f3b42d82aa6b9e9c75",
       "tabbable": null,
       "tooltip": null,
       "value": 400.0
      }
     },
     "32a7c817e60c4f4aaa7c513ed82f6c02": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44133978abc846f2b1b32cce17ce28ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4500671fea39423f8b3f3842c87ce7b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4b263370103945bfad66dfee3b3c7995": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d588b03408448f3b42d82aa6b9e9c75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4fb8a1a86eec41a48cf3df831e95857e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_72c4af9c523f4384834a9d434d0db1a2",
       "max": 133.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_76c1223fe8974c93ba6829c8bec590b5",
       "tabbable": null,
       "tooltip": null,
       "value": 133.0
      }
     },
     "5444163794474ea0879fd8fed07f2dfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6726866c08734b5887acb5f3c4a14f10",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a8c8ac63f2e34c15a0adda9cb9b70d3b",
       "tabbable": null,
       "tooltip": null,
       "value": 50.0
      }
     },
     "54c49081d91e44dcbecf521dfeafb581": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9602eb4c0e9743a8a260ac81b22f645e",
       "placeholder": "​",
       "style": "IPY_MODEL_21ce0462fd334388afbc784426f24e2f",
       "tabbable": null,
       "tooltip": null,
       "value": " 400/400 [00:08&lt;00:00, 63.09 examples/s]"
      }
     },
     "56aa2c94b7d2440c8b51222470ebcb0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5bb4854460464fd6943beb2fe27c41b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "608b93ff9e4549a49f6a969871d89f66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_64f359b246fa4b9383a93887918f4e95",
       "placeholder": "​",
       "style": "IPY_MODEL_839c94d4b4914a7489d9a3e70fca1a52",
       "tabbable": null,
       "tooltip": null,
       "value": " 500/500 [00:36&lt;00:00, 54.27it/s]"
      }
     },
     "62b90d83935e40c082e1460d973b76e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64f359b246fa4b9383a93887918f4e95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6726866c08734b5887acb5f3c4a14f10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "683e8d8700ca40c3bc61712737621211": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "72c4af9c523f4384834a9d434d0db1a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76c1223fe8974c93ba6829c8bec590b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "77914ba056444244a6595735540d690d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d7698dc6e1249269dfa6ac6d0292c9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca5aeba4fa094dac960b5347e64fcd84",
       "max": 500.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1120785e1f51468b902bc044d2823f1e",
       "tabbable": null,
       "tooltip": null,
       "value": 500.0
      }
     },
     "839c94d4b4914a7489d9a3e70fca1a52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "85a9ea41f9fb4b4db77940c8f5775cd7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89715aa6fc9543a684af4cc2767daa6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_62b90d83935e40c082e1460d973b76e7",
       "placeholder": "​",
       "style": "IPY_MODEL_c345d9b1550a47d2bdd605d9779daf92",
       "tabbable": null,
       "tooltip": null,
       "value": "Resolving data files: 100%"
      }
     },
     "8f0c6c1b12cb49ee8c0618bce4b5249c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8fb9be1bae624b2a8e19ad0e10e7492f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9567a3d6f75f429a8b8e104033c95854": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9602eb4c0e9743a8a260ac81b22f645e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98336fe7cb014136a6f9e323fa19da91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98379aa3c7104166baa3400349c1e20e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c669544a27443dea6d72c5354bf9ffa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9eb336052241494390d3463877cc900b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ffd3be55c2da459e8343f781f528b25f",
        "IPY_MODEL_c6e22cb88529458eb596da5a30d739fe",
        "IPY_MODEL_1b0201c4497541f69437fc9d9f61d369"
       ],
       "layout": "IPY_MODEL_98336fe7cb014136a6f9e323fa19da91",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9fe58d4d28b94ce089eca78e434d798e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_89715aa6fc9543a684af4cc2767daa6c",
        "IPY_MODEL_4fb8a1a86eec41a48cf3df831e95857e",
        "IPY_MODEL_23bb17b978414f40af702999478deb65"
       ],
       "layout": "IPY_MODEL_8f0c6c1b12cb49ee8c0618bce4b5249c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a8c8ac63f2e34c15a0adda9cb9b70d3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ba38c7ff37b94d42a3611a138472e47f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f8990abe76d5447eb59455abd750a387",
       "placeholder": "​",
       "style": "IPY_MODEL_5bb4854460464fd6943beb2fe27c41b2",
       "tabbable": null,
       "tooltip": null,
       "value": "Preprocessing: 100%"
      }
     },
     "c345d9b1550a47d2bdd605d9779daf92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c6e22cb88529458eb596da5a30d739fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9567a3d6f75f429a8b8e104033c95854",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_08338bfbcb024bec994b81a310147a61",
       "tabbable": null,
       "tooltip": null,
       "value": 50.0
      }
     },
     "c93d5a511a4a4b24b23a50d5257a01a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_85a9ea41f9fb4b4db77940c8f5775cd7",
       "placeholder": "​",
       "style": "IPY_MODEL_ce79281e146745b78e9f8e6dd459a891",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading samples: 100%"
      }
     },
     "c9bc023300884117bbe056768a3404da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4500671fea39423f8b3f3842c87ce7b9",
       "placeholder": "​",
       "style": "IPY_MODEL_56aa2c94b7d2440c8b51222470ebcb0a",
       "tabbable": null,
       "tooltip": null,
       "value": " 50/50 [00:02&lt;00:00, 11.30 examples/s]"
      }
     },
     "ca5aeba4fa094dac960b5347e64fcd84": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce79281e146745b78e9f8e6dd459a891": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "de169fb7fa8e4485b8ce2afe1dcc0297": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c93d5a511a4a4b24b23a50d5257a01a4",
        "IPY_MODEL_7d7698dc6e1249269dfa6ac6d0292c9f",
        "IPY_MODEL_608b93ff9e4549a49f6a969871d89f66"
       ],
       "layout": "IPY_MODEL_9c669544a27443dea6d72c5354bf9ffa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e0cf74fec1934619864fed2bcd17d103": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e2f3caa244c546a2b78df17a8a770672": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ba38c7ff37b94d42a3611a138472e47f",
        "IPY_MODEL_5444163794474ea0879fd8fed07f2dfc",
        "IPY_MODEL_c9bc023300884117bbe056768a3404da"
       ],
       "layout": "IPY_MODEL_8fb9be1bae624b2a8e19ad0e10e7492f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e3f2348f0d4443ed8086e30a08b1d132": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_77914ba056444244a6595735540d690d",
       "placeholder": "​",
       "style": "IPY_MODEL_e782c971781b4918a29ff0f2b69c8311",
       "tabbable": null,
       "tooltip": null,
       "value": "Preprocessing: 100%"
      }
     },
     "e782c971781b4918a29ff0f2b69c8311": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f8990abe76d5447eb59455abd750a387": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ffc7c80822a04f40acc808eccd6f80a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e3f2348f0d4443ed8086e30a08b1d132",
        "IPY_MODEL_324c7eb3ff924539b36200072c65ef46",
        "IPY_MODEL_54c49081d91e44dcbecf521dfeafb581"
       ],
       "layout": "IPY_MODEL_4b263370103945bfad66dfee3b3c7995",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ffd3be55c2da459e8343f781f528b25f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_98379aa3c7104166baa3400349c1e20e",
       "placeholder": "​",
       "style": "IPY_MODEL_e0cf74fec1934619864fed2bcd17d103",
       "tabbable": null,
       "tooltip": null,
       "value": "Preprocessing: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
